specVersion: v2
specMinorVersion: 1
meta:
  name: mistral-finetune
  image: project-mistral-finetune
  description: An example project for fine-tuning a Mistral model
  labels: []
  createdOn: "2023-11-29T19:40:43Z"
  defaultBranch: main
layout:
- path: code/
  type: code
  storage: git
- path: models/
  type: models
  storage: gitlfs
- path: data/
  type: data
  storage: gitlfs
- path: data/scratch/
  type: data
  storage: gitignore
environment:
  base:
    registry: nvcr.io
    image: nvidia/pytorch:23.12-py3
    build_timestamp: "20231011102429"
    name: PyTorch Basic
    supported_architectures:
    - arm64
    - amd64
    cuda_version: 11.7.0
    description: A Base with CUDA 11.7 and Pytorch 1.13
    entrypoint_script: ""
    labels:
    - cuda11.7
    - pytorch1.13
    apps:
    - name: jupyterlab
      type: jupyterlab
      class: webapp
      start_command: jupyter notebook --allow-root --port 8888 --ip 0.0.0.0 --no-browser
        --NotebookApp.base_url=\$PROXY_PREFIX --NotebookApp.default_url=/lab
      health_check_command: '[ \$(echo url=\$(jupyter notebook list | head -n 2 |
        tail -n 1 | cut -f1 -d'' '' | grep -v ''Currently'' | sed "s@/?@/lab?@g")
        | curl -o /dev/null -s -w ''%{http_code}'' --config -) == ''200'' ]'
      stop_command: jupyter notebook stop 8888
      user_msg: ""
      logfile_path: ""
      timeout_seconds: 0
      icon_url: ""
      webapp_options:
        autolaunch: true
        port: "8888"
        proxy:
          trim_prefix: false
        url_command: jupyter notebook list | head -n 2 | tail -n 1 | cut -f1 -d' '
          | grep -v 'Currently'
    - name: tensorboard
      type: tensorboard
      class: webapp
      start_command: tensorboard --logdir \$TENSORBOARD_LOGS_DIRECTORY --path_prefix=\$PROXY_PREFIX
        --bind_all
      health_check_command: '[ \$(curl -o /dev/null -s -w ''%{http_code}'' http://localhost:\$TENSORBOARD_PORT\$PROXY_PREFIX/)
        == ''200'' ]'
      stop_command: pkill tensorboard
      user_msg: ""
      logfile_path: ""
      timeout_seconds: 0
      icon_url: ""
      webapp_options:
        autolaunch: true
        port: "6006"
        proxy:
          trim_prefix: false
        url: http://localhost:6006
    programming_languages:
    - python3
    icon_url: ""
    image_version: 1.0.13
    os: linux
    os_distro: ubuntu
    os_distro_release: "20.04"
    schema_version: v2
    user_info:
      uid: ""
      gid: ""
      username: ""
    package_managers:
    - name: pip
      binary_path: /opt/conda/bin/pip
      installed_packages: []
    - name: apt
      binary_path: /usr/bin/apt
      installed_packages:
      - build-essential
      - ca-certificates
      - curl
      - locales
      - git
      - git-lfs
      - vim
    - name: conda
      binary_path: /opt/conda/bin/conda
      installed_packages:
      - jupyterlab=3.4.4
      - tensorboard
      - nodejs
      - notebook
      - python=3.10.12
      - pytorch=1.13.1
      - torchvision
      - pytorch-cuda=11.7.0
    package_manager_environment:
      name: ""
      target: ""
execution:
  apps: []
  resources:
    gpu:
      requested: 1
    sharedMemoryMB: 1024
  secrets:
  - variable: HUGGING_FACE_HUB_TOKEN
    description: Hugging Face API Key
  mounts:
  - type: project
    target: /project/
    description: Project directory
    options: rw
  - type: volume
    target: /data/tensorboard/logs/
    description: Tensorboard Log Files
    options: volumeName=tensorboard-logs-volume
  - type: host
    target: /project/models/
    description: Where to save the fine-tuned model on the HOST system
    options: ""
